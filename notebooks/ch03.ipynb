{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVwXnsKPIZMyUq7uHANrZd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/okada-tak/deep-learning-from-scratch-2/blob/master/notebooks/ch03.ipynb)\n",
        "\n",
        "# 3章 word2vec のまとめ\n",
        "- 推論ベースの手法は、推測することを目標として、その副産物として単語の分散表現を得られる\n",
        "- word2vecは推論ベースの手法であり、シンプルな2層のニューラルネットワークで構成される\n",
        "- word2vecには、skip-gramモデルとCBOWモデルがある\n",
        "- CBOWモデルは複数の単語（コンテキスト）からひとつの単語（ターゲット）を推測する\n",
        "- skip-gramモデルは逆に、ひとつの単語（ターゲット）から複数の単語（コンテキスト）を推測する\n",
        "- word2vecは重みの再学習ができるため、単語の分散表現の更新や追加が効率的に行える"
      ],
      "metadata": {
        "id": "xn5qweAY19OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 推論ベースの手法とニューラルネットワーク\n",
        "### 3.1.1 カウントベースの手法の問題点\n",
        "- 語彙数が巨大\n",
        "- 巨大な行列に対してSVD(特異値分解)を行うのは計算量が膨大で非現実的\n",
        "\n",
        "### 3.1.2 推論ベースの手法の概要\n",
        "- モデルはコンテキスト情報を入力として受け取り、各単語の出現する確率を出力する\n",
        "- 正しい推測ができるように、コーパスを使ってモデルの学習を行う\n",
        "- その学習の結果として、単語の分散表現を得られる\n",
        "\n",
        "### 3.1.3 ニューラルネットワークにおける単語の処理方法\n"
      ],
      "metadata": {
        "id": "vhm_QNRJ3jwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "c = np.array([[1,0,0,0,0,0,0]]) # 入力\n",
        "W = np.random.rand(7,3) # 重み\n",
        "h = np.dot(c, W) # 中間ノード：ノード数3\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN7mw3C72zp1",
        "outputId": "77debd60-d504-4b0e-9f78-17feab594f03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.27206189 0.53247467 0.32612566]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S7xI5NCuBHBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ■Colaboratory用\n",
        "Google Colaboratoryの場合、Google Driveに  \n",
        "dl-from-scratch-2/ch03  \n",
        "というフォルダを用意し、そこにこのjupyter notebookを配置。  \n",
        "(dl-from-scratch-3の部分は任意。)  \n",
        "また、datasetフォルダとcommonフォルダを\n",
        "dl-from-scratch-3/dataset  \n",
        "dl-from-scratch-3/common\n",
        "にコピーしておく。  \n",
        "\n",
        "以下のセルでGoogle Driveをマウント。許可を求められるので許可する。"
      ],
      "metadata": {
        "id": "bAN74CQGlIq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aki1Mc1uAzW6",
        "outputId": "6b8b6c50-df85-4e7d-ced9-5b26739d411a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ■Colaboratory用\n",
        "chdirする。"
      ],
      "metadata": {
        "id": "PsIUxRNOBqVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys,os\n",
        "os.chdir('/content/drive/My Drive/dl-from-scratch-2/ch03')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yxdrmnu2BrVJ",
        "outputId": "0b3188c1-2a27-4cce-b94c-46de56a79100"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/dl-from-scratch-2/ch03'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.layers import MatMul\n",
        "\n",
        "c = np.array([[1,0,0,0,0,0,0]])\n",
        "W = np.random.randn(7,3)\n",
        "layer = MatMul(W)\n",
        "h = layer.forward(c)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHbIjm0kBz_A",
        "outputId": "6e52ea60-9daa-4c41-ba6c-61216173cee3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.08332784 -1.22538655 -0.49929668]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 シンプルなword2vec\n",
        "### 3.2.1 CBOWモデルの推論処理\n",
        "CBOW: continuous bag-of-words  \n",
        "ターゲットは中央の単語、その周囲の単語がコンテキスト  \n",
        "$\\text{W}_{\\text{in}}$が重みの行列であり、その各行が各単語の分散表現  \n",
        "\n"
      ],
      "metadata": {
        "id": "PEV7Z2QnCMUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ch03/cbow_predict.py"
      ],
      "metadata": {
        "id": "4tob_Sx6EY4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.layers import MatMul\n",
        "\n",
        "\n",
        "# サンプルのコンテキストデータ\n",
        "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
        "\n",
        "# 重みの初期化\n",
        "W_in = np.random.randn(7, 3)\n",
        "W_out = np.random.randn(3, 7)\n",
        "\n",
        "# レイヤの生成\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "# 順伝搬\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5 * (h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtxJwLxuCJUo",
        "outputId": "03ac802f-b7bf-4a69-ec62-b992e2b8cc68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.4883203  -0.5887907   0.7386593  -0.28155566 -0.34191368  0.61124856\n",
            "   0.01877301]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 CBOWモデルの学習\n",
        "多クラス分類なので、Softmaxと交差エントロピー誤差を使う\n",
        "\n",
        "### 3.2.3 word2vecの重みと分散表現\n",
        "$\\text{W}_{\\text{out}}$も重みの行列であり、その各列が各単語の分散表現  \n",
        "word2vecの特にskip-gramモデルでは入力側の重みだけを利用するのが多い"
      ],
      "metadata": {
        "id": "QILH8ZV4E-Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 学習データの準備"
      ],
      "metadata": {
        "id": "PmXHwQq3GM2e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtHzcIwrGMPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}